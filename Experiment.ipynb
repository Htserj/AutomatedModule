{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование векторного представления элементов и настройка параметров\n",
    "\n",
    "## Корпус справочных элементов и предобработка\n",
    "\n",
    "Корпус справочных элементов представляет собой набор из 264 тысяч записей справочника \"Номенклатуры\"\n",
    "\n",
    "Минимальная предобработка выполнена с помошью библиотекой Python - NLTK и включает в себя следующую последовательность действий:\n",
    "* Удаление пунктуации и знаков\n",
    "* Удаление числовых значений\n",
    "* Приведение слов к нижнему регистру\n",
    "* Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 263740/263740 [00:08<00:00, 30656.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tq\n",
    "\n",
    "data_file = pd.read_csv('./material.csv', sep=';', encoding = 'cp1251', error_bad_lines=False,\n",
    "                        low_memory=False)[['FullName']]\n",
    "\n",
    "data_file = data_file[['FullName']].astype('str')\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "rows = [row[0] for row in data_file.values]\n",
    "\n",
    "words = []\n",
    "for row in tq(rows):\n",
    "    words.extend([i.lower() for i in tokenizer.tokenize(re.sub(r'\\d+', '', row)) if len(i) > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Набор гиперпараметров\n",
    "\n",
    "Параметры | Значения\n",
    "----------| --------\n",
    "Размерность вектора | 25 / 50 / **100** / 200 / 400 / 800\n",
    "Окно | 1 / 2 / 3 / 4 / **5** / 6 / 7 / 8\n",
    "Минимальная частота | 0 / **5** / 10 / 20 / 50 / 100 / 200/400 / 800 / 1000 / 1200 / 2400\n",
    "Негативное семплирование | 1 / 2 / 3 / **5** / 8 /10 / 15\n",
    "Шаг обучения | 0.0125 / **0.025** / 0.05 / 0.1\n",
    "Сэмплирование | 0 / 1e-1 / 1e-2 / **1e-3** / 1e-4 / 1e-5 / 1e-6 / 1e-7 / 1e-8 / 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Внутренняя оценка векторов\n",
    "\n",
    "Внутренняя оценка проводится по методу оценки сходства слов на размечанном корпусе 380 пар для измерения близости элементов спавочника. \n",
    "\n",
    "Элемент справочника $el = \\{w_{1}, w_{2}, ..., w_{k}\\}$, тогда вектор элемента вычисляется по следующей формуле\n",
    "\n",
    "$$\n",
    "x_{el} = \\frac{1}{k}\\sum_{i=1}^{k}w_{i}\n",
    "$$\n",
    "\n",
    "Все пары однозначно определены, следовательно средний показатель косинусной близости должен стремиться к единице для всех примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Внешняя оценка векторов\n",
    "\n",
    "Внешняя оценка проводится с помощью заранее обученного классификатора присвоения бухгалтерского счета. Во время тестирование намеренно не будет поизводится тонкая настройка классификатора и дообучение векторов, в связи с тем чтобы более наглядно продемонстрировать зависимость качетсва классификатора от векторов.\n",
    "\n",
    "Оценивание классификатора проводится по F1-score методу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
